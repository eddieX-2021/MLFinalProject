{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7556af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support,\n",
    "    roc_auc_score, classification_report, confusion_matrix,\n",
    "    RocCurveDisplay\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# optional models\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except Exception:\n",
    "    HAS_XGB = False\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    HAS_LGBM = True\n",
    "except Exception:\n",
    "    HAS_LGBM = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103d32fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (100000, 31)\n",
      "   age  gender ethnicity education_level  income_level employment_status  \\\n",
      "0   58    Male     Asian      Highschool  Lower-Middle          Employed   \n",
      "1   48  Female     White      Highschool        Middle          Employed   \n",
      "2   60    Male  Hispanic      Highschool        Middle        Unemployed   \n",
      "3   74  Female     Black      Highschool           Low           Retired   \n",
      "4   46    Male     White        Graduate        Middle           Retired   \n",
      "\n",
      "  smoking_status  alcohol_consumption_per_week  \\\n",
      "0          Never                             0   \n",
      "1         Former                             1   \n",
      "2          Never                             1   \n",
      "3          Never                             0   \n",
      "4          Never                             1   \n",
      "\n",
      "   physical_activity_minutes_per_week  diet_score  ...  hdl_cholesterol  \\\n",
      "0                                 215         5.7  ...               41   \n",
      "1                                 143         6.7  ...               55   \n",
      "2                                  57         6.4  ...               66   \n",
      "3                                  49         3.4  ...               50   \n",
      "4                                 109         7.2  ...               52   \n",
      "\n",
      "   ldl_cholesterol  triglycerides  glucose_fasting  glucose_postprandial  \\\n",
      "0              160            145              136                   236   \n",
      "1               50             30               93                   150   \n",
      "2               99             36              118                   195   \n",
      "3               79            140              139                   253   \n",
      "4              125            160              137                   184   \n",
      "\n",
      "   insulin_level  hba1c  diabetes_risk_score  diabetes_stage  \\\n",
      "0           6.36   8.18                 29.6          Type 2   \n",
      "1           2.00   5.63                 23.0     No Diabetes   \n",
      "2           5.07   7.51                 44.7          Type 2   \n",
      "3           5.28   9.03                 38.2          Type 2   \n",
      "4          12.74   7.20                 23.5          Type 2   \n",
      "\n",
      "   diagnosed_diabetes  \n",
      "0                   1  \n",
      "1                   0  \n",
      "2                   1  \n",
      "3                   1  \n",
      "4                   1  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/diabetes_dataset.csv\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b84e4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts (0=no, 1=yes):\n",
      " diagnosed_diabetes\n",
      "1    59998\n",
      "0    40002\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "TARGET_COL = \"diagnosed_diabetes\"\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"'{TARGET_COL}' not found in columns: {list(df.columns)[:10]} ...\")\n",
    "\n",
    "# coerce to 0/1 robustly in case dtype is float/bool\n",
    "y = df[TARGET_COL].astype(int).clip(0, 1)\n",
    "print(\"Class counts (0=no, 1=yes):\\n\", y.value_counts())\n",
    "\n",
    "# drop target and any leakage cols if present\n",
    "leakage_like = {\"diabetes_risk_score\", \"diabetes_stage\", TARGET_COL}\n",
    "X = df.drop(columns=[c for c in leakage_like if c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9578a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e54b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [c for c in X_train.columns if X_train[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "def get_transformed_feature_names(fitted_preprocessor):\n",
    "    names = []\n",
    "    if num_cols:\n",
    "        names.extend(num_cols)\n",
    "    if cat_cols:\n",
    "        ohe = fitted_preprocessor.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "        names.extend(list(ohe.get_feature_names_out(cat_cols)))\n",
    "    return np.array(names, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b95cb355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost not installed; skipping XGB model.\n",
      "LightGBM not installed; skipping LGBM model.\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "# logistic Regression (balanced)\n",
    "models.append((\n",
    "    \"LogisticRegression\",\n",
    "    Pipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            max_iter=2000, class_weight=\"balanced\", solver=\"lbfgs\"\n",
    "        ))\n",
    "    ])\n",
    "))\n",
    "\n",
    "# random forest model\n",
    "models.append((\n",
    "    \"RandomForest\",\n",
    "    Pipeline(steps=[\n",
    "        (\"prep\", preprocessor),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=400, max_depth=None, n_jobs=-1,\n",
    "            class_weight=\"balanced_subsample\", random_state=42\n",
    "        ))\n",
    "    ])\n",
    "))\n",
    "\n",
    "# XGBoost (if available) â€” use scale_pos_weight for imbalance\n",
    "if HAS_XGB:\n",
    "    pos = (y_train == 1).sum()\n",
    "    neg = (y_train == 0).sum()\n",
    "    spw = max(1.0, neg / max(pos, 1))\n",
    "    models.append((\n",
    "        \"XGBoost\",\n",
    "        Pipeline(steps=[\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"clf\", XGBClassifier(\n",
    "                n_estimators=500,\n",
    "                learning_rate=0.05,\n",
    "                max_depth=6,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                reg_lambda=1.0,\n",
    "                random_state=42,\n",
    "                eval_metric=\"logloss\",\n",
    "                tree_method=\"hist\",\n",
    "                scale_pos_weight=spw\n",
    "            ))\n",
    "        ])\n",
    "    ))\n",
    "else:\n",
    "    print(\"XGBoost not installed; skipping XGB model.\")\n",
    "\n",
    "# LightGBM (if available)\n",
    "if HAS_LGBM:\n",
    "    models.append((\n",
    "        \"LightGBM\",\n",
    "        Pipeline(steps=[\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"clf\", lgb.LGBMClassifier(\n",
    "                n_estimators=600,\n",
    "                learning_rate=0.05,\n",
    "                num_leaves=63,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42,\n",
    "                class_weight=\"balanced\"\n",
    "            ))\n",
    "        ])\n",
    "    ))\n",
    "else:\n",
    "    print(\"LightGBM not installed; skipping LGBM model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47efc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== LogisticRegression =====\n",
      "Accuracy: 0.8877  |  Precision: 0.9312  |  Recall: 0.8776  |  F1: 0.9036  |  ROC-AUC: 0.9339\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8310    0.9028    0.8654      8000\n",
      "           1     0.9312    0.8776    0.9036     12000\n",
      "\n",
      "    accuracy                         0.8877     20000\n",
      "   macro avg     0.8811    0.8902    0.8845     20000\n",
      "weighted avg     0.8911    0.8877    0.8883     20000\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification report:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, classification_report(y_test, y_pred, digits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m     36\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[0;32m---> 37\u001b[0m \u001b[43mprint_confusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mConfusion Matrix - \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# roc curve\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m proba \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mprint_confusion\u001b[0;34m(cm, title)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprint_confusion\u001b[39m(cm, title):\n\u001b[1;32m      2\u001b[0m     plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m     \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                 xticklabels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPred 0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPred 1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m                 yticklabels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue 0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue 1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(title)\n\u001b[1;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_confusion(cm, title):\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"Pred 0\",\"Pred 1\"],\n",
    "                yticklabels=[\"True 0\",\"True 1\"])\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, pipe in models:\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # preds\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    proba = None\n",
    "    if hasattr(pipe.named_steps[\"clf\"], \"predict_proba\"):\n",
    "        proba = pipe.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(pipe.named_steps[\"clf\"], \"decision_function\"):\n",
    "        # map decision_function to [0,1] with a sigmoid-ish transform\n",
    "        dec = pipe.decision_function(X_test)\n",
    "        proba = (dec - dec.min()) / (dec.max() - dec.min() + 1e-9)\n",
    "\n",
    "    # metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_test, y_pred, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    roc = roc_auc_score(y_test, proba) if proba is not None else np.nan\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}  |  Precision: {prec:.4f}  |  Recall: {rec:.4f}  |  F1: {f1:.4f}  |  ROC-AUC: {roc:.4f}\")\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print_confusion(cm, f\"Confusion Matrix - {name}\")\n",
    "\n",
    "    # roc curve\n",
    "    if proba is not None:\n",
    "        RocCurveDisplay.from_predictions(y_test, proba, name=name)\n",
    "        plt.title(f\"ROC Curve - {name}\")\n",
    "        plt.show()\n",
    "\n",
    "    results.append({\n",
    "        \"model\": name, \"accuracy\": acc, \"precision\": prec,\n",
    "        \"recall\": rec, \"f1\": f1, \"roc_auc\": roc\n",
    "    })\n",
    "\n",
    "# summary table\n",
    "summary = pd.DataFrame(results).sort_values(\"roc_auc\", ascending=False)\n",
    "print(\"\\n===== Model Comparison =====\")\n",
    "print(summary)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(x=\"model\", y=\"roc_auc\", data=summary)\n",
    "plt.title(\"ROC-AUC by Model\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f27510d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_name \u001b[38;5;241m=\u001b[39m \u001b[43msummary\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m best_pipe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(models)[best_name]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mComputing permutation importance for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "best_name = summary.iloc[0][\"model\"]\n",
    "best_pipe = dict(models)[best_name]\n",
    "print(f\"\\nComputing permutation importance for: {best_name}\")\n",
    "\n",
    "best_pipe.fit(X_train, y_train)\n",
    "\n",
    "# get transformed feature names (sklearn >= 1.0)\n",
    "try:\n",
    "    feat_names = best_pipe.named_steps[\"prep\"].get_feature_names_out()\n",
    "except Exception:\n",
    "    # fallback (older sklearn): build names manually\n",
    "    num_feats = np.array(num_cols, dtype=object)\n",
    "    if cat_cols:\n",
    "        ohe = best_pipe.named_steps[\"prep\"].named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "        cat_feats = ohe.get_feature_names_out(cat_cols)\n",
    "        feat_names = np.concatenate([num_feats, cat_feats])\n",
    "    else:\n",
    "        feat_names = num_cols\n",
    "\n",
    "r = permutation_importance(\n",
    "    best_pipe, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1\n",
    ")\n",
    "imp_df = pd.DataFrame({\n",
    "    \"feature\": feat_names,\n",
    "    \"importance_mean\": r.importances_mean,\n",
    "    \"importance_std\": r.importances_std\n",
    "}).sort_values(\"importance_mean\", ascending=False).head(20)\n",
    "\n",
    "print(\"\\nTop 20 permutation importances:\")\n",
    "print(imp_df)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(y=\"feature\", x=\"importance_mean\", data=imp_df)\n",
    "plt.title(f\"Top 20 Permutation Importances - {best_name}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e4d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa9919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f10db3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ad2e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
