{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3f7aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import warnings, json\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    roc_auc_score, f1_score, accuracy_score\n",
    ")\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "# Optional, if installed\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except:\n",
    "    HAS_XGB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "058c3601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version: 1.7.2\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "DATA_PATH = Path(\"../data/fitness.csv\")   # place Kaggle CSV here\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import sklearn\n",
    "\n",
    "print(\"sklearn version:\", sklearn.__version__)  # sanity check\n",
    "\n",
    "def _rmse(y_true, y_pred):\n",
    "    # Works on any sklearn version\n",
    "    try:\n",
    "        return mean_squared_error(y_true, y_pred, squared=False)\n",
    "    except TypeError:\n",
    "        # older versions don't have 'squared' -> compute manually\n",
    "        return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def regression_report(y_true, y_pred):\n",
    "    return {\n",
    "        \"RMSE\": _rmse(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"R2\":  r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "def classification_report_simple(y_true, y_prob, thresh=0.5):\n",
    "    y_hat = (y_prob >= thresh).astype(int)\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_hat),\n",
    "        \"F1\": f1_score(y_true, y_hat),\n",
    "        \"ROC-AUC\": roc_auc_score(y_true, y_prob)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c17d598b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after basic cleaning: 365000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>date</th>\n",
       "      <th>steps</th>\n",
       "      <th>heart_rate_avg</th>\n",
       "      <th>sleep_hours</th>\n",
       "      <th>calories_burned</th>\n",
       "      <th>exercise_minutes</th>\n",
       "      <th>stress_level</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>9341</td>\n",
       "      <td>62.029621</td>\n",
       "      <td>9.368819</td>\n",
       "      <td>2230.230419</td>\n",
       "      <td>0.623979</td>\n",
       "      <td>2</td>\n",
       "      <td>73.496429</td>\n",
       "      <td>22.471978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-09-07</td>\n",
       "      <td>10873</td>\n",
       "      <td>59.062818</td>\n",
       "      <td>6.358311</td>\n",
       "      <td>1840.454777</td>\n",
       "      <td>109.208987</td>\n",
       "      <td>3</td>\n",
       "      <td>68.237867</td>\n",
       "      <td>22.569858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-09-08</td>\n",
       "      <td>6638</td>\n",
       "      <td>58.494078</td>\n",
       "      <td>6.099619</td>\n",
       "      <td>2284.231946</td>\n",
       "      <td>3.083319</td>\n",
       "      <td>4</td>\n",
       "      <td>81.687890</td>\n",
       "      <td>17.595609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-09-09</td>\n",
       "      <td>6062</td>\n",
       "      <td>56.546095</td>\n",
       "      <td>7.584023</td>\n",
       "      <td>1620.464266</td>\n",
       "      <td>22.023327</td>\n",
       "      <td>10</td>\n",
       "      <td>86.379884</td>\n",
       "      <td>20.154137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>F</td>\n",
       "      <td>2024-09-10</td>\n",
       "      <td>10399</td>\n",
       "      <td>59.507172</td>\n",
       "      <td>7.327957</td>\n",
       "      <td>2264.528312</td>\n",
       "      <td>76.483061</td>\n",
       "      <td>8</td>\n",
       "      <td>81.782982</td>\n",
       "      <td>32.624040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age gender       date  steps  heart_rate_avg  sleep_hours  \\\n",
       "0        0   56      F 2024-09-06   9341       62.029621     9.368819   \n",
       "1        0   56      F 2024-09-07  10873       59.062818     6.358311   \n",
       "2        0   56      F 2024-09-08   6638       58.494078     6.099619   \n",
       "3        0   56      F 2024-09-09   6062       56.546095     7.584023   \n",
       "4        0   56      F 2024-09-10  10399       59.507172     7.327957   \n",
       "\n",
       "   calories_burned  exercise_minutes  stress_level  weight_kg        bmi  \n",
       "0      2230.230419          0.623979             2  73.496429  22.471978  \n",
       "1      1840.454777        109.208987             3  68.237867  22.569858  \n",
       "2      2284.231946          3.083319             4  81.687890  17.595609  \n",
       "3      1620.464266         22.023327            10  86.379884  20.154137  \n",
       "4      2264.528312         76.483061             8  81.782982  32.624040  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =======================\n",
    "# 1) Load & sanity check\n",
    "# =======================\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Expected columns (rename here if needed):\n",
    "# user_id, age, gender, date, steps, heart_rate_avg, sleep_hours,\n",
    "# calories_burned, exercise_minutes, stress_level\n",
    "\n",
    "# Normalize/parse\n",
    "if \"date\" in df.columns:\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "if \"gender\" in df.columns:\n",
    "    df[\"gender\"] = df[\"gender\"].astype(str).str.upper().str[:1]  # e.g., 'M'/'F'\n",
    "\n",
    "# Drop rows with missing core signals we rely on\n",
    "core_cols = [\"stress_level\",\"steps\",\"exercise_minutes\",\"sleep_hours\",\"heart_rate_avg\",\"calories_burned\"]\n",
    "for c in core_cols:\n",
    "    if c in df.columns:\n",
    "        df = df[df[c].notna()]\n",
    "\n",
    "# Sort for time-aware operations\n",
    "sort_keys = [c for c in [\"user_id\", \"date\"] if c in df.columns]\n",
    "if sort_keys:\n",
    "    df = df.sort_values(sort_keys)\n",
    "\n",
    "print(\"Rows after basic cleaning:\", len(df))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47b46b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2) Time-aware stress targets (next day)\n",
    "#    - next_day_stress (regression)\n",
    "#    - high_stress_next (classification, e.g., >= 7)\n",
    "# ==========================================\n",
    "grp = df.groupby(\"user_id\", group_keys=False) if \"user_id\" in df.columns else [(None, df)]\n",
    "\n",
    "def add_targets(g, threshold=7):\n",
    "    g = g.sort_values(\"date\") if \"date\" in g.columns else g\n",
    "    if \"stress_level\" in g.columns:\n",
    "        g[\"next_day_stress\"] = g[\"stress_level\"].shift(-1)\n",
    "        g[\"high_stress_next\"] = (g[\"next_day_stress\"] >= threshold).astype(\"Int64\")\n",
    "    return g\n",
    "\n",
    "if isinstance(grp, pd.core.groupby.generic.DataFrameGroupBy):\n",
    "    df = grp.apply(add_targets)\n",
    "else:\n",
    "    df = add_targets(df)\n",
    "\n",
    "# Remove last day per user (no next-day target)\n",
    "df = df[df[\"next_day_stress\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5aa6cc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model rows after lag/rolling & dropna: 357000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>next_day_stress</th>\n",
       "      <th>high_stress_next</th>\n",
       "      <th>stress_level_lag1</th>\n",
       "      <th>stress_level_lag2</th>\n",
       "      <th>stress_level_lag7</th>\n",
       "      <th>stress_level_roll3_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>heart_rate_avg_lag7</th>\n",
       "      <th>heart_rate_avg_roll3_mean</th>\n",
       "      <th>heart_rate_avg_roll7_mean</th>\n",
       "      <th>heart_rate_avg_roll7_std</th>\n",
       "      <th>calories_burned_lag1</th>\n",
       "      <th>calories_burned_lag2</th>\n",
       "      <th>calories_burned_lag7</th>\n",
       "      <th>calories_burned_roll3_mean</th>\n",
       "      <th>calories_burned_roll7_mean</th>\n",
       "      <th>calories_burned_roll7_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-13</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>62.029621</td>\n",
       "      <td>53.656194</td>\n",
       "      <td>56.728742</td>\n",
       "      <td>5.381481</td>\n",
       "      <td>2226.499339</td>\n",
       "      <td>1660.834309</td>\n",
       "      <td>2230.230419</td>\n",
       "      <td>2050.620653</td>\n",
       "      <td>2018.177624</td>\n",
       "      <td>299.247239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-14</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>59.062818</td>\n",
       "      <td>52.841562</td>\n",
       "      <td>56.019264</td>\n",
       "      <td>4.869140</td>\n",
       "      <td>2353.914903</td>\n",
       "      <td>2226.499339</td>\n",
       "      <td>1840.454777</td>\n",
       "      <td>2080.416184</td>\n",
       "      <td>2035.846836</td>\n",
       "      <td>316.980858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-15</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>58.494078</td>\n",
       "      <td>57.077810</td>\n",
       "      <td>55.879228</td>\n",
       "      <td>4.780304</td>\n",
       "      <td>2469.393097</td>\n",
       "      <td>2353.914903</td>\n",
       "      <td>2284.231946</td>\n",
       "      <td>2349.935780</td>\n",
       "      <td>2125.695167</td>\n",
       "      <td>340.621107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-16</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>56.546095</td>\n",
       "      <td>58.987648</td>\n",
       "      <td>56.353946</td>\n",
       "      <td>5.227352</td>\n",
       "      <td>1574.421061</td>\n",
       "      <td>2469.393097</td>\n",
       "      <td>1620.464266</td>\n",
       "      <td>2132.576354</td>\n",
       "      <td>2024.293612</td>\n",
       "      <td>387.928200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-17</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>59.507172</td>\n",
       "      <td>57.907565</td>\n",
       "      <td>55.964936</td>\n",
       "      <td>5.311318</td>\n",
       "      <td>2094.353869</td>\n",
       "      <td>1574.421061</td>\n",
       "      <td>2264.528312</td>\n",
       "      <td>2046.056009</td>\n",
       "      <td>2091.992127</td>\n",
       "      <td>344.644360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id       date gender  age  next_day_stress  high_stress_next  \\\n",
       "7         0 2024-09-13      F   56             10.0                 1   \n",
       "8         0 2024-09-14      F   56              7.0                 1   \n",
       "9         0 2024-09-15      F   56             10.0                 1   \n",
       "10        0 2024-09-16      F   56              3.0                 0   \n",
       "11        0 2024-09-17      F   56              4.0                 0   \n",
       "\n",
       "    stress_level_lag1  stress_level_lag2  stress_level_lag7  \\\n",
       "7                 7.0                1.0                2.0   \n",
       "8                 3.0                7.0                3.0   \n",
       "9                10.0                3.0                4.0   \n",
       "10                7.0               10.0               10.0   \n",
       "11               10.0                7.0                8.0   \n",
       "\n",
       "    stress_level_roll3_mean  ...  heart_rate_avg_lag7  \\\n",
       "7                  5.333333  ...            62.029621   \n",
       "8                  3.666667  ...            59.062818   \n",
       "9                  6.666667  ...            58.494078   \n",
       "10                 6.666667  ...            56.546095   \n",
       "11                 9.000000  ...            59.507172   \n",
       "\n",
       "    heart_rate_avg_roll3_mean  heart_rate_avg_roll7_mean  \\\n",
       "7                   53.656194                  56.728742   \n",
       "8                   52.841562                  56.019264   \n",
       "9                   57.077810                  55.879228   \n",
       "10                  58.987648                  56.353946   \n",
       "11                  57.907565                  55.964936   \n",
       "\n",
       "    heart_rate_avg_roll7_std  calories_burned_lag1  calories_burned_lag2  \\\n",
       "7                   5.381481           2226.499339           1660.834309   \n",
       "8                   4.869140           2353.914903           2226.499339   \n",
       "9                   4.780304           2469.393097           2353.914903   \n",
       "10                  5.227352           1574.421061           2469.393097   \n",
       "11                  5.311318           2094.353869           1574.421061   \n",
       "\n",
       "    calories_burned_lag7  calories_burned_roll3_mean  \\\n",
       "7            2230.230419                 2050.620653   \n",
       "8            1840.454777                 2080.416184   \n",
       "9            2284.231946                 2349.935780   \n",
       "10           1620.464266                 2132.576354   \n",
       "11           2264.528312                 2046.056009   \n",
       "\n",
       "    calories_burned_roll7_mean  calories_burned_roll7_std  \n",
       "7                  2018.177624                 299.247239  \n",
       "8                  2035.846836                 316.980858  \n",
       "9                  2125.695167                 340.621107  \n",
       "10                 2024.293612                 387.928200  \n",
       "11                 2091.992127                 344.644360  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 3) Lag & rolling features (leakage-safe, per user)\n",
    "#    Use only past info to predict tomorrow's stress.\n",
    "# =====================================================\n",
    "def make_lags_rolls(g, cols_numeric, lags=(1, 2, 7), rolls=((3, \"mean\"), (7, \"mean\"), (7, \"std\"))):\n",
    "    g = g.sort_values(\"date\") if \"date\" in g.columns else g\n",
    "    for c in cols_numeric:\n",
    "        if c not in g.columns: \n",
    "            continue\n",
    "        for L in lags:\n",
    "            g[f\"{c}_lag{L}\"] = g[c].shift(L)\n",
    "        for win, agg in rolls:\n",
    "            if agg == \"mean\":\n",
    "                g[f\"{c}_roll{win}_mean\"] = g[c].shift(1).rolling(win, min_periods=2).mean()\n",
    "            elif agg == \"std\":\n",
    "                g[f\"{c}_roll{win}_std\"] = g[c].shift(1).rolling(win, min_periods=3).std()\n",
    "    return g\n",
    "\n",
    "num_source_cols = [c for c in [\n",
    "    \"stress_level\",\"steps\",\"exercise_minutes\",\"sleep_hours\",\"heart_rate_avg\",\"calories_burned\"\n",
    "] if c in df.columns]\n",
    "\n",
    "if isinstance(grp, pd.core.groupby.generic.DataFrameGroupBy):\n",
    "    df = df.groupby(\"user_id\", group_keys=False).apply(\n",
    "        make_lags_rolls, cols_numeric=num_source_cols\n",
    "    )\n",
    "else:\n",
    "    df = make_lags_rolls(df, num_source_cols)\n",
    "\n",
    "# After creating lags/rolls, build modeling frame\n",
    "feature_cols = [c for c in df.columns if any(x in c for x in [\"_lag\", \"_roll\"])]\n",
    "keep_cols = [\"user_id\",\"date\",\"gender\",\"age\",\"next_day_stress\",\"high_stress_next\"] + feature_cols\n",
    "keep_cols = [c for c in keep_cols if c in df.columns]\n",
    "df_model = df[keep_cols].dropna().copy()\n",
    "\n",
    "print(\"Model rows after lag/rolling & dropna:\", len(df_model))\n",
    "display(df_model.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff35a369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff date: 2025-06-25\n",
      "Train/Val rows: 286000  Test rows: 71000\n",
      "Train rows: 258000  Val rows: 28000\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# 4) Time split (80% oldest → train/val; 20% newest → test)\n",
    "# =====================================\n",
    "assert \"date\" in df_model.columns, \"Need a date column for time-aware split.\"\n",
    "cutoff = df_model[\"date\"].quantile(0.80)\n",
    "df_trainval = df_model[df_model[\"date\"] <= cutoff].copy()\n",
    "df_test     = df_model[df_model[\"date\"] >  cutoff].copy()\n",
    "\n",
    "print(\"Cutoff date:\", cutoff.date())\n",
    "print(\"Train/Val rows:\", len(df_trainval), \" Test rows:\", len(df_test))\n",
    "\n",
    "# Build validation from last 10% of trainval time\n",
    "cutoff_tv = df_trainval[\"date\"].quantile(0.90)\n",
    "df_train = df_trainval[df_trainval[\"date\"] <= cutoff_tv].copy()\n",
    "df_val   = df_trainval[df_trainval[\"date\"] >  cutoff_tv].copy()\n",
    "\n",
    "print(\"Train rows:\", len(df_train), \" Val rows:\", len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b164ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REG | Linear (VAL): {'RMSE': np.float64(2.8745620897056137), 'MAE': 2.5040251018101856, 'R2': -0.00013277682597512275}\n",
      "REG | Linear (TEST): {'RMSE': np.float64(2.8664242143775134), 'MAE': 2.49406384080066, 'R2': 6.107036323166337e-05}\n",
      "REG | RF (VAL): {'RMSE': np.float64(2.8786294845687537), 'MAE': 2.504368285714286, 'R2': -0.0029650780792833675}\n",
      "REG | RF (TEST): {'RMSE': np.float64(2.870848853699674), 'MAE': 2.493772366197183, 'R2': -0.003028342456031119}\n",
      "REG | XGB (VAL): {'RMSE': np.float64(2.887785315693779), 'MAE': 2.507820689865521, 'R2': -0.009355329217192399}\n",
      "REG | XGB (TEST): {'RMSE': np.float64(2.8772211679415833), 'MAE': 2.4948136238783176, 'R2': -0.007486052162677614}\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 5) REGRESSION: next_day_stress\n",
    "# ===========================\n",
    "target_reg = \"next_day_stress\"\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# ---- drop non-feature ID columns ----\n",
    "drop_cols = [\"date\", target_reg, \"high_stress_next\", \"user_id\"]  # add other IDs if present\n",
    "X_train_r = df_train.drop(columns=drop_cols, errors=\"ignore\")\n",
    "y_train_r = df_train[target_reg]\n",
    "\n",
    "X_val_r   = df_val.drop(columns=drop_cols, errors=\"ignore\")\n",
    "y_val_r   = df_val[target_reg]\n",
    "\n",
    "X_test_r  = df_test.drop(columns=drop_cols, errors=\"ignore\")\n",
    "y_test_r  = df_test[target_reg]\n",
    "\n",
    "# optional: ensure 'age' is numeric if it came in as string\n",
    "for c in [\"age\"]:\n",
    "    if c in X_train_r.columns:\n",
    "        X_train_r[c] = pd.to_numeric(X_train_r[c], errors=\"coerce\")\n",
    "        X_val_r[c]   = pd.to_numeric(X_val_r[c], errors=\"coerce\")\n",
    "        X_test_r[c]  = pd.to_numeric(X_test_r[c], errors=\"coerce\")\n",
    "\n",
    "num_cols = [c for c in X_train_r.columns if pd.api.types.is_numeric_dtype(X_train_r[c])]\n",
    "cat_cols = [c for c in X_train_r.columns if c not in num_cols]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, num_cols),\n",
    "    (\"cat\", categorical_pipe, cat_cols)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "\n",
    "# Baseline 1: Linear Regression\n",
    "lin_r = Pipeline([(\"pre\", pre), (\"model\", LinearRegression())])\n",
    "lin_r.fit(X_train_r, y_train_r)\n",
    "pred_val_lin = lin_r.predict(X_val_r)\n",
    "pred_test_lin = lin_r.predict(X_test_r)\n",
    "print(\"REG | Linear (VAL):\", regression_report(y_val_r, pred_val_lin))\n",
    "print(\"REG | Linear (TEST):\", regression_report(y_test_r, pred_test_lin))\n",
    "\n",
    "# Baseline 2: Random Forest\n",
    "rf_r = Pipeline([(\"pre\", pre), (\"model\", RandomForestRegressor(\n",
    "    n_estimators=500, max_depth=None, random_state=RANDOM_SEED, n_jobs=-1\n",
    "))])\n",
    "rf_r.fit(X_train_r, y_train_r)\n",
    "pred_val_rf = rf_r.predict(X_val_r)\n",
    "pred_test_rf = rf_r.predict(X_test_r)\n",
    "print(\"REG | RF (VAL):\", regression_report(y_val_r, pred_val_rf))\n",
    "print(\"REG | RF (TEST):\", regression_report(y_test_r, pred_test_rf))\n",
    "\n",
    "# Optional 3: XGBoost\n",
    "if HAS_XGB:\n",
    "    xgb_r = Pipeline([(\"pre\", pre), (\"model\", xgb.XGBRegressor(\n",
    "        n_estimators=800, max_depth=6, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        random_state=RANDOM_SEED, n_jobs=-1\n",
    "    ))])\n",
    "    xgb_r.fit(X_train_r, y_train_r)\n",
    "    pred_val_xgb = xgb_r.predict(X_val_r)\n",
    "    pred_test_xgb = xgb_r.predict(X_test_r)\n",
    "    print(\"REG | XGB (VAL):\", regression_report(y_val_r, pred_val_xgb))\n",
    "    print(\"REG | XGB (TEST):\", regression_report(y_test_r, pred_test_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e076fb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLF | LogReg (VAL): {'Accuracy': 0.5009642857142858, 'F1': 0.4427072946994775, 'ROC-AUC': 0.5003722004728373}\n",
      "CLF | LogReg (TEST): {'Accuracy': 0.5049295774647887, 'F1': 0.44744867482000816, 'ROC-AUC': 0.5056521623732576}\n",
      "CLF | RF (VAL): {'Accuracy': 0.5957142857142858, 'F1': 0.0001766472354707649, 'ROC-AUC': 0.49835082375795475}\n",
      "CLF | RF (TEST): {'Accuracy': 0.5991549295774647, 'F1': 0.0001405283867341203, 'ROC-AUC': 0.5022863891369723}\n",
      "CLF | XGB (VAL): {'Accuracy': 0.5929285714285715, 'F1': 0.029461852861035424, 'ROC-AUC': 0.5009192098617925}\n",
      "CLF | XGB (TEST): {'Accuracy': 0.5957887323943662, 'F1': 0.0314535452735311, 'ROC-AUC': 0.5021451563007668}\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 6) CLASSIFICATION: high_stress_next (>=7)\n",
    "# ===========================\n",
    "if \"high_stress_next\" in df_train.columns:\n",
    "    target_clf = \"high_stress_next\"\n",
    "\n",
    "    X_train_c = df_train.drop(columns=[\"date\", target_clf, \"next_day_stress\"], errors=\"ignore\")\n",
    "    y_train_c = df_train[target_clf].astype(int)\n",
    "\n",
    "    X_val_c   = df_val.drop(columns=[\"date\", target_clf, \"next_day_stress\"], errors=\"ignore\")\n",
    "    y_val_c   = df_val[target_clf].astype(int)\n",
    "\n",
    "    X_test_c  = df_test.drop(columns=[\"date\", target_clf, \"next_day_stress\"], errors=\"ignore\")\n",
    "    y_test_c  = df_test[target_clf].astype(int)\n",
    "\n",
    "    # Logistic Regression (balanced)\n",
    "    logit = Pipeline([(\"pre\", pre), (\"model\", LogisticRegression(\n",
    "        max_iter=2000, class_weight=\"balanced\"\n",
    "    ))])\n",
    "    logit.fit(X_train_c, y_train_c)\n",
    "    val_prob = logit.predict_proba(X_val_c)[:,1]\n",
    "    test_prob = logit.predict_proba(X_test_c)[:,1]\n",
    "    print(\"CLF | LogReg (VAL):\", classification_report_simple(y_val_c, val_prob))\n",
    "    print(\"CLF | LogReg (TEST):\", classification_report_simple(y_test_c, test_prob))\n",
    "\n",
    "    # Random Forest Classifier\n",
    "    rf_c = Pipeline([(\"pre\", pre), (\"model\", RandomForestClassifier(\n",
    "        n_estimators=500, max_depth=None, random_state=RANDOM_SEED, n_jobs=-1, class_weight=\"balanced\"\n",
    "    ))])\n",
    "    rf_c.fit(X_train_c, y_train_c)\n",
    "    val_prob_rf = rf_c.predict_proba(X_val_c)[:,1]\n",
    "    test_prob_rf = rf_c.predict_proba(X_test_c)[:,1]\n",
    "    print(\"CLF | RF (VAL):\", classification_report_simple(y_val_c, val_prob_rf))\n",
    "    print(\"CLF | RF (TEST):\", classification_report_simple(y_test_c, test_prob_rf))\n",
    "\n",
    "    # Optional XGBClassifier\n",
    "    if HAS_XGB:\n",
    "        xgb_c = Pipeline([(\"pre\", pre), (\"model\", xgb.XGBClassifier(\n",
    "            n_estimators=800, max_depth=6, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            random_state=RANDOM_SEED, n_jobs=-1,\n",
    "            eval_metric=\"auc\", scale_pos_weight=None\n",
    "        ))])\n",
    "        xgb_c.fit(X_train_c, y_train_c)\n",
    "        val_prob_xgb = xgb_c.predict_proba(X_val_c)[:,1]\n",
    "        test_prob_xgb = xgb_c.predict_proba(X_test_c)[:,1]\n",
    "        print(\"CLF | XGB (VAL):\", classification_report_simple(y_val_c, val_prob_xgb))\n",
    "        print(\"CLF | XGB (TEST):\", classification_report_simple(y_test_c, test_prob_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa6e3ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gender=F] n=36281 | RMSE=2.87 MAE=2.49 R2=-0.003\n",
      "[gender=M] n=34719 | RMSE=2.87 MAE=2.49 R2=-0.004\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# 7) Simple fairness / slice checks\n",
    "# =======================================\n",
    "def print_reg_slice(dfX, y_true, y_pred, name):\n",
    "    rep = regression_report(y_true, y_pred)\n",
    "    print(f\"[{name}] n={len(dfX)} | RMSE={rep['RMSE']:.2f} MAE={rep['MAE']:.2f} R2={rep['R2']:.3f}\")\n",
    "\n",
    "if \"gender\" in X_test_r.columns:\n",
    "    for g in sorted(X_test_r[\"gender\"].dropna().unique()):\n",
    "        idx = (X_test_r[\"gender\"]==g)\n",
    "        print_reg_slice(X_test_r[idx], y_test_r[idx], pred_test_rf[idx], f\"gender={g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a158ddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifacts/metrics_stress.json\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 8) Save lightweight artifacts\n",
    "# ===========================\n",
    "Path(\"artifacts\").mkdir(exist_ok=True)\n",
    "out = {\n",
    "    \"reg_linear_test\": regression_report(y_test_r, pred_test_lin),\n",
    "    \"reg_rf_test\": regression_report(y_test_r, pred_test_rf)\n",
    "}\n",
    "if HAS_XGB:\n",
    "    out[\"reg_xgb_test\"] = regression_report(y_test_r, pred_test_xgb)\n",
    "with open(\"artifacts/metrics_stress.json\",\"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "print(\"Saved artifacts/metrics_stress.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a249416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d652af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-fitness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
